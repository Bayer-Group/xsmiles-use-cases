{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perturb-based vs. SHAP-based attributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "Here we explore SMILES-based attributions calculated with the Substitution (CDDD), and atom-based attributions calculated with SHAP (Morgan), and _Riniker and Landrum_ method (Morgan).\n",
    "\n",
    "LogP per atom is used to create a reference set of attributions that we can compare with attributions from XAI methods calculated with different models.\n",
    "\n",
    "\n",
    "### How to run this notebook\n",
    "\n",
    "Note that you need **JupyterLab** to see the visualization - it may not work in other environments\n",
    "\n",
    "You can run All cells and it will load the models and molecules, and then display the visualizations.\n",
    "\n",
    "By default, the cells with the heavier parts (model training, etc.) have a flag set to False, so they are ignored and uses pre-computed data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CDDD: https://github.com/jrwnter/cddd\n",
    "\n",
    "250 mol dataset: https://github.com/jensengroup/FP_RF_XAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citation\n",
    "\n",
    "If you use this use case, Substitution method, attributions, or visualizations, please cite XSMILES (URL TBD) and xBCF (URL TBD)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Pre-trained CatBoost models\n",
    "logp_model_path = \"../data/logp_model.joblib\"\n",
    "logp_model_path_morgan = \"../data/logp_morgan_model.joblib\"\n",
    "\n",
    "\n",
    "# saves the embeddings calculated with CDDD\n",
    "data_w_cddd_emb_path = \"../data/emb.npz\"\n",
    "\n",
    "# general imports\n",
    "import numpy as np\n",
    "np.random.rand(56234)\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "# access to /src code\n",
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "\n",
    "import random\n",
    "random.seed(56234)\n",
    "\n",
    "from cddd.inference import InferenceModel\n",
    "from cddd.preprocessing import preprocess_smiles\n",
    "from chem_util import smiles_to_mols\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "\n",
    "\n",
    "\n",
    "def standardize_smiles_list(smiles_list):\n",
    "    return [preprocess_smiles(s) for s in smiles_list]\n",
    "\n",
    "def preprocess(df):\n",
    "    n_smiles = len(df.smiles.values.tolist())\n",
    "    smiles_list = df.smiles.values.tolist()\n",
    "    mols, successful_inds = smiles_to_mols(smiles_list)\n",
    "    df['logp'] = [Descriptors.MolLogP(i) for i in mols]\n",
    "    df['smiles'] = standardize_smiles_list(df.smiles.values.tolist())\n",
    "    df = df.dropna()\n",
    "    df['smiles'] = df['smiles'].astype(str)    \n",
    "    print(\"Ignored molecules due to problematic smiles or null logp/charges:\", n_smiles-len(df.smiles.tolist()))\n",
    "    df = df.reset_index()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# load CDDD default model\n",
    "# This package is not official. We compiled the original project in a way \n",
    "# that the python code and model are combined into one package, \n",
    "# so you don't need to worry about copying folders here and there.\n",
    "from cddd.inference import InferenceModel\n",
    "cddd_model = InferenceModel(use_gpu=False, cpu_threads=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training data\n",
    "1. Load the source data to get the SMILES and target values\n",
    "2. Add LogP, Max LogP and Min LogP columns to the data frame.\n",
    "3. Load the CDDD model and generate embeddings to npz file. (save as file to save time for future runs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>smiles</th>\n",
       "      <th>logp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1</td>\n",
       "      <td>5.05060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CC1CC(C)CC(Nc2cncc(-c3nncn3C)c2)C1</td>\n",
       "      <td>3.11370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>N#Cc1ccc(-c2ccc(OC(C(=O)N3CCCC3)c3ccccc3)cc2)cc1</td>\n",
       "      <td>4.96778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>CCOC(=O)C1CCCN(C(=O)c2nc(-c3ccc(C)cc3)n3c2CCCC...</td>\n",
       "      <td>4.00022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>N#CC1=C(SCC(=O)Nc2cccc(Cl)c2)N=C([O-])C(C#N)C1...</td>\n",
       "      <td>3.60956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index                                             smiles  \\\n",
       "0           0      0            CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1   \n",
       "1           1      1                 CC1CC(C)CC(Nc2cncc(-c3nncn3C)c2)C1   \n",
       "2           2      2   N#Cc1ccc(-c2ccc(OC(C(=O)N3CCCC3)c3ccccc3)cc2)cc1   \n",
       "3           3      3  CCOC(=O)C1CCCN(C(=O)c2nc(-c3ccc(C)cc3)n3c2CCCC...   \n",
       "4           4      4  N#CC1=C(SCC(=O)Nc2cccc(Cl)c2)N=C([O-])C(C#N)C1...   \n",
       "\n",
       "      logp  \n",
       "0  5.05060  \n",
       "1  3.11370  \n",
       "2  4.96778  \n",
       "3  4.00022  \n",
       "4  3.60956  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SET to True if you want to preprocess again - the data was already stored in other format after preprocessing the original\n",
    "prepare_data = False\n",
    "\n",
    "small_data_test = False # Set to true to run a quick test (sample 2% data from the entire set)\n",
    "\n",
    "df = None\n",
    "if prepare_data:\n",
    "    # ZINC_250k.smi original data from: https://github.com/jensengroup/FP_RF_XAI \n",
    "    # Unzip from our data/ZINC_250K.smi.zip\n",
    "    df = pd.read_csv(\"../data/ZINC_250k.smi\")\n",
    "    if small_data_test:\n",
    "        df = df = df.sample(frac=0.02).reset_index(drop=True)\n",
    "    \n",
    "    df = preprocess(df)    \n",
    "\n",
    "    if small_data_test:\n",
    "        df.to_csv('../data/test_mols_logp.csv') \n",
    "    else:\n",
    "        df.to_csv('../data/250k_mols_logp.csv')  \n",
    "       \n",
    "    print(len(df))\n",
    "    df.head()\n",
    "else:\n",
    "    if small_data_test:\n",
    "        df = pd.read_csv(\"../data/test_mols_logp.csv\")\n",
    "    else:\n",
    "        df = pd.read_csv(\"../data/250k_mols_logp.csv\") \n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249437\n"
     ]
    }
   ],
   "source": [
    "smiles_list = df.smiles.values.tolist()\n",
    "ids = range(len(smiles_list)) #df.iupac.values.tolist()\n",
    "\n",
    "logp = df.logp.values.tolist()\n",
    "\n",
    "print(len(smiles_list))\n",
    "\n",
    "data_size = len(ids)\n",
    "perm_idx = np.random.permutation(data_size)\n",
    "train_idx = perm_idx[:int(0.8*data_size)] \n",
    "test_idx = perm_idx[int(0.8*data_size):] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.show(df.hist(column=\"logp\", bins=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chem_util import calc_morgan_counts_for_mol\n",
    "from fp_xai.fp_xai import mol2fp\n",
    "from rdkit import Chem\n",
    "def calc_morgan_fingerprints(smiles_list):\n",
    "    mols = [Chem.MolFromSmiles(smiles_string, sanitize=True) for smiles_string in smiles_list]\n",
    "    #featuresMorganCounts = [calc_morgan_counts_for_mol(mol, radius=1, nBits=2048) for mol in mols]\n",
    "    fingerprints = [mol2fp(mol, radius=1, n_bits=2048) for mol in mols]\n",
    "    columns = [\"fp_morgan_counts_\" + str(i) for i in range(2048)]\n",
    "    fingerprints = pd.DataFrame(fingerprints, columns=columns)\n",
    "    return(fingerprints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to true if you don't have emb.npz in /data \n",
    "generate_cddd = False \n",
    "\n",
    "if generate_cddd:\n",
    "    print(\"Calculating CDDD Embeddings and Morgan Fingerprints...\")\n",
    "    embeddings = cddd_model.seq_to_emb(smiles_list)\n",
    "    \n",
    "    morgan_fingerprints = calc_morgan_fingerprints(smiles_list)\n",
    "    \n",
    "    np.savez_compressed(\n",
    "        data_w_cddd_emb_path,\n",
    "        bid=ids,\n",
    "        smiles=smiles_list,\n",
    "        embeddings=embeddings,\n",
    "        morgan_fingerprints=morgan_fingerprints,\n",
    "        logp=logp,           \n",
    "    )\n",
    "    print(\"CDDD Embeddings and Morgan Fingerprints generated and saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Models\n",
    "\n",
    "1. Load the embedding file\n",
    "2. Train-test split\n",
    "3. Scale the target\n",
    "4. Training\n",
    "5. Testing\n",
    "6. Train a final model on the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET to True if you want to retrain models\n",
    "train_models = False # if you want to train the models, please set generate_cddd=True, you need to generate the embeddings \n",
    "\n",
    "if train_models:\n",
    "    all_data = np.load(data_w_cddd_emb_path, allow_pickle=True) # dataframe with embeddings\n",
    "\n",
    "\n",
    "    smiles_list = all_data['smiles']\n",
    "    embs = all_data['embeddings']\n",
    "    morgan_fingerprints =  all_data['morgan_fingerprints']\n",
    "    ids = all_data['bid']\n",
    "\n",
    "    # logp\n",
    "    logp = all_data['logp']\n",
    "\n",
    "\n",
    "    data_size\n",
    "    type(embs), embs.shape, type(logp), logp.shape, len(train_idx), len(test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from catboost import CatBoostRegressor\n",
    "import joblib\n",
    "\n",
    "def build_model(train_x, test_x, train_y, test_y, model, save_model_path, save=False):\n",
    "    #wrapped_model = TransformedTargetRegressor(regressor=model, transformer=MinMaxScaler())\n",
    "    wrapped_model = model\n",
    "    wrapped_model.fit(train_x, train_y)\n",
    "    \n",
    "    model_name = save_model_path.replace(\"../data/\",\"\").replace(\"_model.joblib\",\"\")\n",
    "    min_y = min([min(train_y), min(test_y)])\n",
    "    max_y = max([max(train_y), max(test_y)])\n",
    "    print(min_y, max_y)\n",
    "\n",
    "    yhat = wrapped_model.predict(train_x)\n",
    "    min_yh = min([min_y, min(yhat)])*1.2\n",
    "    max_yh = max([max_y, max(yhat)])*1.2\n",
    "    r2 = r2_score(train_y, yhat)    \n",
    "    plt.scatter(yhat, train_y)\n",
    "    plt.xlim(min_yh, max_yh)\n",
    "    plt.ylim(min_yh, max_yh)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.title(model_name + \" - Train (R2: \"+str(r2)+\")\")    \n",
    "    plt.show()\n",
    "\n",
    "    if save:\n",
    "        joblib.dump(wrapped_model, save_model_path)\n",
    "    return wrapped_model\n",
    "\n",
    "model = CatBoostRegressor(iterations=10000, depth=6, thread_count=-1, random_seed=4514134, silent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_test(yhat, test_y, model_name):\n",
    "    min_y = min(test_y)\n",
    "    max_y = max(test_y)\n",
    "    print(min_y, max_y)\n",
    "    min_yh = min([min_y, min(yhat)])*1.2\n",
    "    max_yh = max([max_y, max(yhat)])*1.2\n",
    "    r2 = r2_score(test_y, yhat)  \n",
    "    rmse = mean_squared_error(test_y, yhat)\n",
    "    plt.scatter(yhat, test_y)\n",
    "    plt.xlim(min_yh, max_yh)\n",
    "    plt.ylim(min_yh, max_yh)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.title(model_name + \" - Test (R2: \"+str(r2)+\", RMSE: \"+str(rmse)+\")\")\n",
    "    plt.show()\n",
    "\n",
    "def test_model(test_y, yhat, model_name):\n",
    "    \n",
    "    plot_test(yhat, test_y, model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.base import clone\n",
    "\n",
    "logpModelMorgan = None\n",
    "logpModel = None\n",
    "# RFmodel = None\n",
    "\n",
    "# import pickle \n",
    "# if RFmodel == None:\n",
    "#     RFmodel = pickle.load(open(\"../data/150000_200_3_2048.p\", 'rb'))\n",
    "\n",
    "\n",
    "if train_models:\n",
    "    # MORGAN_FINGERPRINTS-based\n",
    "    train_x_morgan, test_x_morgan = morgan_fingerprints[train_idx, :], morgan_fingerprints[test_idx, :]\n",
    "    try:\n",
    "        model = model.copy()\n",
    "    except:\n",
    "        model = clone(model)\n",
    "    logpModelMorgan = build_model( train_x=train_x_morgan, \n",
    "                train_y=logp[train_idx], \n",
    "                test_x=test_x_morgan, \n",
    "                test_y=logp[test_idx], \n",
    "                model=model,\n",
    "                save_model_path=logp_model_path_morgan,\n",
    "                save=True\n",
    "            )\n",
    "\n",
    "    # #SMILES CDDD-based\n",
    "    train_x, test_x = embs[train_idx, :], embs[test_idx, :]\n",
    "    try:\n",
    "        model = model.copy()\n",
    "    except:\n",
    "        model = clone(model)\n",
    "    logpModel = build_model(train_x=train_x, \n",
    "                train_y=logp[train_idx], \n",
    "                test_x=test_x, \n",
    "                test_y=logp[test_idx], \n",
    "                model=model,\n",
    "                save_model_path=logp_model_path,\n",
    "                save=True\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_saved_models = False # if you want to print graphics about testing results\n",
    "    \n",
    "# Morgan    \n",
    "logpModelMorgan = joblib.load(logp_model_path_morgan)\n",
    "if test_saved_models:    \n",
    "    test_x_morgan = morgan_fingerprints[test_idx, :]\n",
    "    model_name = logp_model_path_morgan.replace(\"../data/\",\"\").replace(\"_model.joblib\",\"\")\n",
    "    yhat = logpModelMorgan.predict(test_x_morgan)\n",
    "    test_model(test_y=logp[test_idx], yhat=yhat, model_name=model_name) #test_y, yhat, model_name\n",
    "\n",
    "# CDDD\n",
    "logpModel = joblib.load(logp_model_path)  \n",
    "if test_saved_models:    \n",
    "    test_x = embs[test_idx, :]\n",
    "    model_name = logp_model_path.replace(\"../data/\",\"\").replace(\"_model.joblib\",\"\")\n",
    "    yhat = logpModel.predict(test_x)        \n",
    "    test_model(test_y=logp[test_idx], yhat=yhat, model_name=model_name) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: although the difference between Morgan (bits) and CDDD is big in the graphics above, this difference was not found when we used **Morgan Counts** (hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attributor.attributor import Attributor\n",
    "import json\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import rdMolDescriptors, AllChem, MolFromSmiles\n",
    "\n",
    "def get_crippen(mol):\n",
    "    contribs = rdMolDescriptors._CalcCrippenContribs(mol)\n",
    "    return [contrib[0] for contrib in contribs]\n",
    "\n",
    "def calc_logp_crippen_contribs(smiles_list):\n",
    "    mols, _ = smiles_to_mols(smiles_list)\n",
    "\n",
    "    logp_contribs = [get_crippen(mol) for mol in mols]\n",
    "\n",
    "    return logp_contribs#, logp\n",
    "\n",
    "import shap\n",
    "from chem_util import atom_attributions, calc_indices_for_fingerprints\n",
    "\n",
    "# if RFmodel == None:\n",
    "#     RFmodel = pickle.load(open(\"../data/150000_200_3_2048.p\", 'rb'))\n",
    "\n",
    "global_smiles_list = np.array(smiles_list)\n",
    "def shap_attributions(model, smiles_local_list):\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    all_attributions = []\n",
    "    mols, _ = smiles_to_mols(smiles_local_list)\n",
    "    for i in range(len(smiles_local_list)):\n",
    "        x_local = None\n",
    "        x_local = calc_morgan_fingerprints([smiles_local_list[i]]).iloc[0].to_numpy()\n",
    "\n",
    "        # current rdkit mol\n",
    "        mol = mols[i]        \n",
    "\n",
    "        # compute shap\n",
    "        shap_vals_list = explainer.shap_values([x_local])    \n",
    "        shap_vals = shap_vals_list[0] # we only have 1 mol here\n",
    "        # print(\"SHAP\", shap_vals_list)\n",
    "\n",
    "        indices = calc_indices_for_fingerprints(smiles_local_list[i], radius = 1, nBits=2048)         \n",
    "        featureNames = [\"fp_morgan_counts_\" +  str(k) for k in range(len(x_local))]\n",
    "        attrs = atom_attributions(mol=mol, indices=indices, shap_vals=shap_vals, featureNames=featureNames, direction=\"both\")\n",
    "        \n",
    "        all_attributions.append(attrs)\n",
    "    return all_attributions\n",
    "\n",
    "def get_gasteiger_charges(smiles):\n",
    "    mol = MolFromSmiles(smiles, sanitize = True)\n",
    "    AllChem.ComputeGasteigerCharges(mol)\n",
    "    charges_contribs = [mol.GetAtomWithIdx(j).GetDoubleProp('_GasteigerCharge')  for j in range(mol.GetNumAtoms())]\n",
    "    return charges_contribs\n",
    "\n",
    "def cal_attributions_xsmiles_single_mols(smiles_local_list):\n",
    "            \n",
    "    attr_logp_crippen = calc_logp_crippen_contribs(smiles_local_list)\n",
    "\n",
    "    # XAI: SMILES Perturbation\n",
    "    attr_logp, _ = Attributor(logpModel, cddd_model).smiles_attribution(smiles_local_list)\n",
    "\n",
    "    # XAI: SHAP\n",
    "    attr_logp_SHAP = shap_attributions(logpModelMorgan, smiles_local_list)\n",
    "\n",
    "    attributions = []\n",
    "    for i in range(len(smiles_local_list)):                \n",
    "        smiles_string = smiles_local_list[i]        \n",
    "        mol = MolFromSmiles(smiles_string, sanitize = True)\n",
    "\n",
    "        global_index = None\n",
    "        morgan_x_instance = None\n",
    "        logp_calculated = None\n",
    "        if smiles_string in global_smiles_list:\n",
    "            global_index = np.where(global_smiles_list == smiles_string)[0][0]\n",
    "          \n",
    "       \n",
    "        morgan_x_instance = calc_morgan_fingerprints([smiles_string]).iloc[0].to_numpy()\n",
    "        logp_calculated = Descriptors.MolLogP(mol)\n",
    "\n",
    "        from fp_xai.fp_xai import get_weights_for_visualization               \n",
    "        ml_weights, atom_weights, fpa_weights, logp_pred_rl = get_weights_for_visualization(mol, logpModelMorgan, radius=1, n_bits=2048) # this must be radius 2 because it was trained with that by the original authors of the model. It was also trained with 150k mols instead of 250k.\n",
    "\n",
    "        #Riniker and Landrum\n",
    "        riniker_landrum_method = {\n",
    "            'attributes': {\n",
    "                    'logp': logp_calculated, \n",
    "                    'pred': logp_pred_rl,\n",
    "            },\n",
    "            'name': 'Morgan-R&L',\n",
    "            'scores': ml_weights.tolist()\n",
    "         }\n",
    "\n",
    "        normalized_crippen_method = {\n",
    "            'attributes': {\n",
    "                    'logp': logp_calculated, \n",
    "                    'pred': ' ',\n",
    "            },\n",
    "            'name': 'Normalized Crippen',\n",
    "            'scores': atom_weights.tolist()\n",
    "        }\n",
    "\n",
    "        fpa_method = {\n",
    "            'attributes': {\n",
    "                    'logp': logp_calculated, \n",
    "                    'pred': ' ',\n",
    "            },\n",
    "            'name': 'FPA',\n",
    "            'scores': fpa_weights.tolist()\n",
    "        }\n",
    "\n",
    "\n",
    "        logp_perturb_method = {\n",
    "            'attributes': {\n",
    "                    'logp': logp_calculated, \n",
    "                    'pred': attr_logp[i]['attributes']['predicted_value'],\n",
    "            },\n",
    "            'name': 'CDDD-Substitution',\n",
    "            'scores': attr_logp[i]['methods'][0]['scores']\n",
    "         }\n",
    "\n",
    "        logp_shap_method = {\n",
    "            'attributes': {\n",
    "                    'logp': logp_calculated, \n",
    "                    'pred': logpModelMorgan.predict(morgan_x_instance),\n",
    "            },\n",
    "            'name': 'Morgan-SHAP',\n",
    "            'scores': attr_logp_SHAP[i].tolist()\n",
    "         }\n",
    "\n",
    "        logp_crippen_method = {\n",
    "            'attributes': {\n",
    "                    'logp': logp_calculated, \n",
    "                    'pred': ' ',\n",
    "            },\n",
    "            'name': 'Crippen',\n",
    "            'scores': attr_logp_crippen[i]\n",
    "         }\n",
    "\n",
    "        methods = [logp_crippen_method, normalized_crippen_method, fpa_method, logp_perturb_method, logp_shap_method, riniker_landrum_method]\n",
    "\n",
    "        xsmilesMol = {\n",
    "                    'string': smiles_string,\n",
    "                    'methods': methods, \n",
    "                    'attributes': {'name': ids[global_index] if global_index != None else 'myMol'}}       \n",
    "\n",
    "        attributions.append(xsmilesMol)\n",
    "        print(\"Concluded: \", smiles_string)\n",
    "    return attributions    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_small_smiles(smiles_list, max_size=10):\n",
    "  return [smiles for smiles in smiles_list if len(smiles) <= max_size]\n",
    "\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "\n",
    "def chunks(l, n):   \n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "def save_xsmiles_molecules(smiles_list, chunk_size=20):\n",
    "    smiles_chunks = list(chunks(smiles_list, chunk_size))    \n",
    "    for i in range(len(smiles_chunks)):                \n",
    "        print(\"Chunk \"+str(i+1)+\"/\"+str(len(smiles_chunks)))\n",
    "        xsmilesMols = cal_attributions_xsmiles_single_mols(smiles_chunks[i])\n",
    "        with open(\"../data/attributions_chunk_\"+str(i+1)+\".json\", \"w\") as jf:\n",
    "            json.dump(xsmilesMols, jf, cls=NpEncoder)\n",
    "\n",
    "\n",
    "from random import randint\n",
    "def find_smiles(smiles_list, model, max_error = 0.03):\n",
    "    list_size = len(smiles_list)\n",
    "    error = 1\n",
    "    while error > max_error:\n",
    "        smiles = smiles_list[randint(0,list_size-1)]\n",
    "        mol = Chem.MolFromSmiles(smiles, sanitize=True)\n",
    "        x_morgan = mol2fp(mol, radius=1, n_bits=2048)\n",
    "        pred = model.predict(x_morgan)\n",
    "        calc = Descriptors.MolLogP(mol)\n",
    "        error = abs((max(pred,calc)-min(pred,calc))/calc)\n",
    "    return smiles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to rerun the attributions methods set it to True. NOTE: it may take many minutes.\n",
    "from re import search\n",
    "\n",
    "\n",
    "re_run_attributions = False\n",
    "\n",
    "vancomycin = 'CC1C(C(CC(O1)OC2C(C(C(OC2OC3=C4C=C5C=C3OC6=C(C=C(C=C6)C(C(C(=O)NC(C(=O)NC5C(=O)NC7C8=CC(=C(C=C8)O)C9=C(C=C(C=C9O)O)C(NC(=O)C(C(C1=CC(=C(O4)C=C1)Cl)O)NC7=O)C(=O)O)CC(=O)N)NC(=O)C(CC(C)C)NC)O)Cl)CO)O)O)(C)N)O'\n",
    "rifampicin = 'CC1C=CC=C(C(=O)NC2=C(C3=C(C4=C(C(=C3O)C)OC(C4=O)(OC=CC(C(C(C(C(C(C1O)C)O)C)OC(=O)C)C)OC)C)C(=O)C2=CNN5CCN(CC5)C)O)C'\n",
    "azithromycin = 'CC[C@H]1OC(=O)[C@H](C)[C@@H](O[C@H]2C[C@@](C)(OC)[C@@H](O)[C@H](C)O2)[C@H](C)[C@@H](O[C@@H]2O[C@H](C)C[C@H](N(C)C)[C@H]2O)[C@](C)(O)C[C@@H](C)CN(C)[C@H](C)[C@@H](O)[C@]1(C)O'\n",
    "\n",
    "# use_case_2 = ['CCn1cc(CN2CCN(CC[NH+]3C(C)CCC3C)CC2)cn1', 'O=C(Nc1ccc(F)cc1)[C@@H]1CC(=O)N(c2ccc(Cl)cc2)C1']\n",
    "use_case_2 = [\n",
    "    'O=Cc1cc(OCc2ccccc2)ccc1Br', # example: correct most important atom, but inverted signal direction for all the oxigens (note: low score)\n",
    "    'COC(=O)c1ccccc1-c1nc(-c2ccccc2)no1',\n",
    "    'CC(C)(C)OC(=O)NCC(O)c1ccc(Cl)cc1Cl',\n",
    "    'COCCC(C)NC(=O)c1sc(C)c(Br)c1OC',\n",
    "    'O=C(Nc1ccc(F)cc1)[C@@H]1CC(=O)N(c2ccc(Cl)cc2)C1'\n",
    "    ]\n",
    "\n",
    "antibiotics = [vancomycin, rifampicin, azithromycin]\n",
    "\n",
    "common_replacements = ['C1=C(C=CN=N1)C', 'C1(=[N]C=CC=[N]1)C']\n",
    "\n",
    "\n",
    "symmetry = [\n",
    "                'Nc1ccc(-c2ccc(N)cc2)cc1', # N  CX LogP:  1.96 https://www.ebi.ac.uk/chembl/compound_report_card/CHEMBL15901/\n",
    "                'Oc1ccc(-c2ccc(O)cc2)cc1', # O  CX LogP:  3.01 https://www.ebi.ac.uk/chembl/compound_report_card/CHEMBL76398/\n",
    "                    'c1ccc(-c2ccccc2)cc1', # -- CX LogP:  3.62 https://www.ebi.ac.uk/chembl/compound_report_card/CHEMBL14092/\n",
    "              'Clc1ccc(-c2ccc(Cl)cc2)cc1', # Cl CX LogP:  4.83 https://www.ebi.ac.uk/chembl/compound_report_card/CHEMBL14295/\n",
    "              'Brc1ccc(-c2ccc(Br)cc2)cc1'  # Br CX LogP:  5.16 https://www.ebi.ac.uk/chembl/compound_report_card/CHEMBL8166/\n",
    "            ]\n",
    "\n",
    "if re_run_attributions:  \n",
    "    # These molecules are always included in the list that will be visualized.\n",
    "    # you can change or add more...\n",
    "    \n",
    "    my_molecules = [] #use_case_2#symmetry#[] #[*use_case_2, *diff_atoms, *common_replacements] #[azithromycin]#[logp_article_mol] \n",
    "\n",
    "    print(my_molecules)\n",
    "    # Set the number of molecules that are random sampled from the dataset\n",
    "    # The notebook will use those to visualize with XSMILES\n",
    "    total_n_molecules = 2    \n",
    "\n",
    "    chunk_size = 20 # each file may get too many molecules, we recoment < 50 molecules per file if you are using it with the Demo Website.\n",
    "    # Here setting it to 5 means 5 x 6 scores-methods = max. 30 molecule diagrams per JSON file.\n",
    "\n",
    "    random_molecules = []\n",
    "    smiles_to_attr = my_molecules\n",
    "    test_set_smiles = get_small_smiles(global_smiles_list[test_idx], max_size=20)\n",
    "    \n",
    "    print(\"Test smiles size (<41chars):\", len(test_set_smiles))\n",
    "    if total_n_molecules != 0:\n",
    "        n_molecules_to_search = total_n_molecules-len(my_molecules)\n",
    "        smiles_set = set()        \n",
    "        while len(smiles_set) < n_molecules_to_search:\n",
    "            smiles = find_smiles(test_set_smiles, logpModelMorgan, max_error = 0.1)\n",
    "            smiles_set.add(smiles)\n",
    "\n",
    "        #random_molecules = random.sample(global_smiles_list.tolist(), n_molecules_to_search)            \n",
    "        smiles_to_attr = [*my_molecules, *list(smiles_set)]\n",
    "    \n",
    "    #smiles_to_attr = standardize_smiles_list(smiles_to_attr)  ### this was not working for the antibiotics listed above\n",
    "   \n",
    "    save_xsmiles_molecules(smiles_to_attr, chunk_size=chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Attributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the `XSMILES User Manual` notebook from XSMILES's GitHub repository to learn how to set up the visualization if you don't want to stick to the default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XSMILES version: 0.2.1\n"
     ]
    }
   ],
   "source": [
    "import xsmiles\n",
    "import json\n",
    "print(\"XSMILES version:\", xsmiles.__version__) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the molecules and attributions from the JSON file that was saved in the previous section (`Generate Attributions`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open('../data/symmetries.json')\n",
    "# f = open('../data/antibiotics.json')\n",
    "f = open('../data/attributions_chunk_1.json')  # Here we saved in a JSON file, but you could use the molecules and attributions directly without saving.\n",
    "\n",
    "molecules = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize molecules using XSMILES with default settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11fdf853c741484991bed986a2eae19a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "XSmilesWidget(molecules='[{\"string\": \"OC1CCC2CCC(O)CC2C1\", \"methods\": [{\"attributes\": {\"logp\": 1.3084, \"pred\":…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Currently XSMILES widget only accepts the python dict in json-text format. \n",
    "# Use json.dumps() as here:\n",
    "xsmiles.XSmilesWidget(molecules=json.dumps(molecules))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up `view_config` and `gradient_config` to customize the XSMILES Visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "view_config = {\n",
    "    'hideBarChart':False,\n",
    "    'hideAttributesTable': False, \n",
    "    'showScoresOnStructure':False,    \n",
    "}\n",
    "\n",
    "gradient_config = {        \n",
    "    'palette': 'PiYG_5_reverse',     # <palette>_reverse  \n",
    "    'colorDomain': [-0.00001, 0, 0.00001], # Highlight what is positive versus what is negative - it's a way of ignoring magnitude in the XSMILES\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "350960b836c54b8b85f05792b1577c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "XSmilesWidget(gradient_config='{\"palette\": \"PiYG_5_reverse\", \"colorDomain\": [-1e-05, 0, 1e-05]}', molecules='[…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xsmiles.XSmilesWidget(molecules=json.dumps(molecules), gradient_config=json.dumps(gradient_config), view_config=json.dumps(view_config) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change `view_config` to show SMILES, XAI attributions onto the structure, and `colorDomain` to local `[-max, 0, max]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e73bc567705044dfb845282b3e26b4bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "XSmilesWidget(gradient_config='{\"palette\": \"PiYG_5_reverse\", \"colorDomain\": [-0.2, 0, 0.2]}', molecules='[{\"st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_config = {\n",
    "    'hideBarChart':False,\n",
    "    'hideAttributesTable': False, \n",
    "    'showScoresOnStructure': True\n",
    "}\n",
    "\n",
    "gradient_config = {  \n",
    "    'palette': 'PiYG_5_reverse', # <palette>_reverse    \n",
    "    'colorDomain': [-0.20,0, 0.20], # Note that this is highlighting anything above 0.25 (below -0.25). Check the next example of config to see how to define \"local color domain per molecule\".\n",
    "}\n",
    "\n",
    "xsmiles.XSmilesWidget(molecules=json.dumps(molecules), gradient_config=json.dumps(gradient_config), view_config=json.dumps(view_config) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e67533e3aa45ceade2b1cf570685e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "XSmilesWidget(gradient_config='{\"thresholds\": [], \"highlight\": false, \"palette\": \"PiYG_5_reverse\", \"colorDomai…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gradient_config = {    \n",
    "    'thresholds': [], # default: []\n",
    "    'highlight': False, #default: False\n",
    "    'palette': 'PiYG_5_reverse',  \n",
    "    'colorDomain': [], # default:[] - use the local absolute max score to define each molecule's colorDomain\n",
    "}\n",
    "\n",
    "xsmiles.XSmilesWidget(molecules=json.dumps(molecules), gradient_config=json.dumps(gradient_config), view_config=json.dumps(view_config) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "new_smiles = cddd_model.emb_to_seq(cddd_model.seq_to_emb(\"COC[NH+]1CCCC(O)C1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'COC[NH+]1CCCC(O)C1'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing CC\n",
      "Concluded:  CC\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'string': 'CC',\n",
       "  'methods': [{'attributes': {'logp': 1.0262, 'pred': ' '},\n",
       "    'name': 'Crippen',\n",
       "    'scores': [0.1441, 0.1441]},\n",
       "   {'attributes': {'logp': 1.0262, 'pred': ' '},\n",
       "    'name': 'Normalized Crippen',\n",
       "    'scores': [0.5131, 0.5131]},\n",
       "   {'attributes': {'logp': 1.0262, 'pred': ' '},\n",
       "    'name': 'FPA',\n",
       "    'scores': [0.5131, 0.5131]},\n",
       "   {'attributes': {'logp': 1.0262, 'pred': 2.749623572694591},\n",
       "    'name': 'CDDD-Substitution',\n",
       "    'scores': [0.6166033294105513, 0.626469338215172]},\n",
       "   {'attributes': {'logp': 1.0262, 'pred': 1.4045981476702263},\n",
       "    'name': 'Morgan-SHAP',\n",
       "    'scores': [0.00023476444622710376, 0.00023476444622710376]},\n",
       "   {'attributes': {'logp': 1.0262, 'pred': 1.4045981476702263},\n",
       "    'name': 'Morgan-R&L',\n",
       "    'scores': [0.7022990738351131, 0.7022990738351131]}],\n",
       "  'attributes': {'name': 'myMol'}}]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mols = cal_attributions_xsmiles_single_mols([\"CC\"])\n",
    "mols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed3151633a04567b9769b819ae1e847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "XSmilesWidget(molecules='[{\"string\": \"CC\", \"methods\": [{\"attributes\": {\"logp\": 1.0262, \"pred\": \" \"}, \"name\": \"…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xsmiles.XSmilesWidget(molecules=json.dumps(mols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b2c09bebc978ccfa2b566c6d9838b00db2fa4b2769255a701f1c05b9ef0794ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
